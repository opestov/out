{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST, Hello world"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data\n",
    "\n",
    "Kaggle has a competition https://www.kaggle.com/c/digit-recognizer where it provides three files:\n",
    "\n",
    "1. train.csv\n",
    "2. test.csv\n",
    "3. sample_submission.csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data Into SQLite DB\n",
    "\n",
    "Instead of loading data from csv files, I am going to load it from a SQLite database.\n",
    "\n",
    "    sqlite3 mnist.db\n",
    "    sqlite> .import --csv train.csv train\n",
    "    sqlite> select count(1) from train;\n",
    "    42000\n",
    "    sqlite> select 0.2 * 42000;\n",
    "    8400.0\n",
    "    sqlite> create temp view z as select rowid from train order by random() limit 8400;\n",
    "    sqlite> create table v as select rowid as id, * from train where rowid in z order by random();\n",
    "    sqlite> create table t as select rowid as id, * from train where rowid not in z order by random();\n",
    "\n",
    "I shuffle and divide images into training and validation datasets. Id column is used to reference original images.\n",
    "\n",
    "Columns that were created during import has a text type.\n",
    "\n",
    "    sqlite> .schema train\n",
    "    CREATE TABLE train(\n",
    "      \"label\" TEXT,\n",
    "      \"pixel0\" TEXT,\n",
    "      \"pixel1\" TEXT,\n",
    "      ...\n",
    "      \"pixel782\" TEXT,\n",
    "      \"pixel783\" TEXT\n",
    "    );  \n",
    "\n",
    "I need to remember to convert corresponding values from string to int when accessing data. The alternative would be to create table with correct types and then import but I will left this approach for another day.\n",
    "\n",
    "Also import test dataset:\n",
    "\n",
    "    sqlite> .import --csv test.csv test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib, sqlite3, torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DbDataset(torch.utils.data.IterableDataset):  \n",
    "    def __init__(self, db, table, transform, limit = 10000):\n",
    "        self.db, self.limit, self.offset = db, limit, 0\n",
    "        self.transform = transform\n",
    "        self.select = f\"SELECT * FROM {table} LIMIT ? OFFSET ?\"\n",
    "        \n",
    "    def __iter__(self):\n",
    "        select, db, limit = self.select, self.db, self.limit\n",
    "        self.buf = []\n",
    "        while True:\n",
    "            if len(self.buf) == 0:\n",
    "                with contextlib.closing(sqlite3.connect(db)) as c:\n",
    "                    r = c.cursor().execute(select, (limit, self.offset))\n",
    "                    self.offset += limit\n",
    "                    self.buf = r.fetchall()\n",
    "                if len(self.buf) == 0:\n",
    "                    break\n",
    "                self.buf.reverse()\n",
    "            yield self.transform(self.buf.pop())           \n",
    "\n",
    "def trainTransform(t):\n",
    "    y = int(t[1])\n",
    "    X = torch.as_tensor(list(map(int, t[2:])), dtype=torch.float) / 255.\n",
    "    return (X, y)\n",
    "    \n",
    "def testTransform(t):\n",
    "    return torch.as_tensor(list(map(int, t)), dtype=torch.float) / 255.\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simplest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "model = torch.nn.Linear(28 * 28, 10)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I've trained this model for 10 epochs. The final accuracy is ~0.9. Kaggle's score is also ~0.9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy():\n",
    "    ds = DbDataset(\"mnist.db\", \"v\", trainTransform)\n",
    "    dl = torch.utils.data.DataLoader(ds, batch_size=256)\n",
    "    c, total = 0, 0\n",
    "    for i, target in dl:\n",
    "        r = torch.argmax(model(i), dim=1) == target\n",
    "        c += int(torch.sum(r))\n",
    "        total += r.shape[0]\n",
    "    return c / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch():\n",
    "    ds = DbDataset(\"mnist.db\", \"t\", trainTransform)\n",
    "    dl = torch.utils.data.DataLoader(ds, batch_size=256)\n",
    "    c, total = 0, 0\n",
    "    for i, target in dl:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(i)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    for _ in range(10):\n",
    "        epoch()\n",
    "        print(accuracy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "\n",
    "def write_results():\n",
    "    ds = DbDataset(\"mnist.db\", \"test\", testTransform)\n",
    "    r = []\n",
    "    for i in ds:\n",
    "        r.append(int(torch.argmax(model(i))))\n",
    "    with open('subm.csv', 'w') as f:    \n",
    "        fieldnames = ['ImageId', 'Label']\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "\n",
    "        writer.writeheader()\n",
    "        for i, j in enumerate(r):\n",
    "            writer.writerow({'ImageId': i + 1, 'Label': j})    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
